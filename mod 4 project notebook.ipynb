{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Nick Oseland \n",
    "* Student pace: self paced \n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Eli Thomas\n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s understand how to do an approach for multiclass classification for text data in Python through identify the type of news based on headlines and short descriptions.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Text or document classification is a machine learning technique used to assigning text documents into one or more classes, among a predefined set of classes. A text classification system would successfully be able to classify each document to its correct class based on inherent properties of the text.\n",
    "\n",
    "We will use Kaggle’s News Category Dataset to build a categories classifier with the libraries sklearn and keras for deep learning. This dataset contains around 200k news headlines from the year 2012 to 2018 obtained from HuffPost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Load the data, and all the libraries to start with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "np.random.seed(0)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to download the data from the kaggle site, then we can use the following function to load the dataset and to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40171\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23341</th>\n",
       "      <td></td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>Jared Kushner Arrives In Israel For Whirlwind ...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jared-kus...</td>\n",
       "      <td>It remains unclear what approach the White Hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100639</th>\n",
       "      <td>JamesMichael Nichols</td>\n",
       "      <td>QUEER VOICES</td>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>'The Best Thing Is To See How Much Love Can Do...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/stacy-hol...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184179</th>\n",
       "      <td>Party Earth, Contributor\\nContributor</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>2012-07-25</td>\n",
       "      <td>Berlin's Nightlife: 48 Hours You Might Not Rem...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/berlins-n...</td>\n",
       "      <td>If you think spending time boozing and schmooz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136649</th>\n",
       "      <td>Shelly Ulaj, Contributor\\nFounder and CEO of W...</td>\n",
       "      <td>DIVORCE</td>\n",
       "      <td>2013-12-13</td>\n",
       "      <td>Finding Strength to Stand on Your Own</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/finding-s...</td>\n",
       "      <td>I was so used to being taken care of by family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196185</th>\n",
       "      <td>Ellie Krupnick</td>\n",
       "      <td>STYLE &amp; BEAUTY</td>\n",
       "      <td>2012-03-18</td>\n",
       "      <td>Alexander Wang Lawsuit Will Move To Federal Co...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/alexander...</td>\n",
       "      <td>Representatives of Alexander Wang's brand cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  authors        category  \\\n",
       "23341                                                            POLITICS   \n",
       "100639                               JamesMichael Nichols    QUEER VOICES   \n",
       "184179              Party Earth, Contributor\\nContributor          TRAVEL   \n",
       "136649  Shelly Ulaj, Contributor\\nFounder and CEO of W...         DIVORCE   \n",
       "196185                                     Ellie Krupnick  STYLE & BEAUTY   \n",
       "\n",
       "             date                                           headline  \\\n",
       "23341  2017-06-21  Jared Kushner Arrives In Israel For Whirlwind ...   \n",
       "100639 2015-01-23  'The Best Thing Is To See How Much Love Can Do...   \n",
       "184179 2012-07-25  Berlin's Nightlife: 48 Hours You Might Not Rem...   \n",
       "136649 2013-12-13              Finding Strength to Stand on Your Own   \n",
       "196185 2012-03-18  Alexander Wang Lawsuit Will Move To Federal Co...   \n",
       "\n",
       "                                                     link  \\\n",
       "23341   https://www.huffingtonpost.com/entry/jared-kus...   \n",
       "100639  https://www.huffingtonpost.com/entry/stacy-hol...   \n",
       "184179  https://www.huffingtonpost.com/entry/berlins-n...   \n",
       "136649  https://www.huffingtonpost.com/entry/finding-s...   \n",
       "196185  https://www.huffingtonpost.com/entry/alexander...   \n",
       "\n",
       "                                        short_description  \n",
       "23341   It remains unclear what approach the White Hou...  \n",
       "100639                                                     \n",
       "184179  If you think spending time boozing and schmooz...  \n",
       "136649  I was so used to being taken care of by family...  \n",
       "196185  Representatives of Alexander Wang's brand cont...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('News_Category_Dataset_v2.json', lines=True)\n",
    "df = df.sample(frac=0.2) # for now, once things are working, I will run without\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['authors', 'category', 'date', 'headline', 'link', 'short_description'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40171 entries, 23341 to 112248\n",
      "Data columns (total 6 columns):\n",
      "authors              40171 non-null object\n",
      "category             40171 non-null object\n",
      "date                 40171 non-null datetime64[ns]\n",
      "headline             40171 non-null object\n",
      "link                 40171 non-null object\n",
      "short_description    40171 non-null object\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40171</td>\n",
       "      <td>40171</td>\n",
       "      <td>40171</td>\n",
       "      <td>40171</td>\n",
       "      <td>40171</td>\n",
       "      <td>40171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9809</td>\n",
       "      <td>41</td>\n",
       "      <td>2309</td>\n",
       "      <td>40006</td>\n",
       "      <td>40171</td>\n",
       "      <td>35926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2014-02-24 00:00:00</td>\n",
       "      <td>Sunday Roundup</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/rex-tille...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7366</td>\n",
       "      <td>6477</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>3914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors  category                 date        headline  \\\n",
       "count    40171     40171                40171           40171   \n",
       "unique    9809        41                 2309           40006   \n",
       "top             POLITICS  2014-02-24 00:00:00  Sunday Roundup   \n",
       "freq      7366      6477                   32              22   \n",
       "first      NaN       NaN  2012-01-28 00:00:00             NaN   \n",
       "last       NaN       NaN  2018-05-26 00:00:00             NaN   \n",
       "\n",
       "                                                     link short_description  \n",
       "count                                               40171             40171  \n",
       "unique                                              40171             35926  \n",
       "top     https://www.huffingtonpost.com/entry/rex-tille...                    \n",
       "freq                                                    1              3914  \n",
       "first                                                 NaN               NaN  \n",
       "last                                                  NaN               NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 41 catagories in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['category'].value_counts().plot( kind='bar', figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIME' 'ENTERTAINMENT' 'WORLD NEWS' 'IMPACT' 'POLITICS' 'WEIRD NEWS'\n",
      " 'BLACK VOICES' 'WOMEN' 'COMEDY' 'QUEER VOICES' 'SPORTS' 'BUSINESS'\n",
      " 'TRAVEL' 'MEDIA' 'TECH' 'RELIGION' 'SCIENCE' 'LATINO VOICES' 'EDUCATION'\n",
      " 'COLLEGE' 'PARENTS' 'ARTS & CULTURE' 'STYLE' 'GREEN' 'TASTE'\n",
      " 'HEALTHY LIVING' 'THE WORLDPOST' 'GOOD NEWS' 'WORLDPOST' 'FIFTY' 'ARTS'\n",
      " 'WELLNESS' 'PARENTING' 'HOME & LIVING' 'STYLE & BEAUTY' 'DIVORCE'\n",
      " 'WEDDINGS' 'FOOD & DRINK' 'MONEY' 'ENVIRONMENT' 'CULTURE & ARTS']\n"
     ]
    }
   ],
   "source": [
    "print(df['category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to combine 'THE WORLDPOST' with 'WORLDPOST' since they are basically the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.category = df.category.map(lambda x: 'WORLDPOST' if x== 'THE WORLDPOST' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27993</td>\n",
       "      <td>40</td>\n",
       "      <td>2309</td>\n",
       "      <td>199344</td>\n",
       "      <td>200812</td>\n",
       "      <td>178353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2013-01-17 00:00:00</td>\n",
       "      <td>Sunday Roundup</td>\n",
       "      <td>https://www.huffingtonpost.comhttp://www.purpo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36620</td>\n",
       "      <td>32739</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>19712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors  category                 date        headline  \\\n",
       "count   200853    200853               200853          200853   \n",
       "unique   27993        40                 2309          199344   \n",
       "top             POLITICS  2013-01-17 00:00:00  Sunday Roundup   \n",
       "freq     36620     32739                  100              90   \n",
       "first      NaN       NaN  2012-01-28 00:00:00             NaN   \n",
       "last       NaN       NaN  2018-05-26 00:00:00             NaN   \n",
       "\n",
       "                                                     link short_description  \n",
       "count                                              200853            200853  \n",
       "unique                                             200812            178353  \n",
       "top     https://www.huffingtonpost.comhttp://www.purpo...                    \n",
       "freq                                                    2             19712  \n",
       "first                                                 NaN               NaN  \n",
       "last                                                  NaN               NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "Since we're working with text data, we'll still need to do some basic preprocessing and tokenize our data. You'll notice from the sample of the data above that two different columns contain text data--headline and short_description. The more text data our Word2Vec model has, the better it will perform. Therefore, we'll want to combine the two columns before tokenizing each comment and training our Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a while, a lot of data...\n",
    "target = df.category\n",
    "df['combined_text'] = df.headline + ' ' +  df.short_description\n",
    "data = df['combined_text'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading A Pretrained GloVe Model\n",
    "I will be loading the pretrained weights from GloVe (short for Global Vectors for Word Representation) from the Stanford NLP Group. These are commonly accepted as some of the best pre-trained word vectors available, and they're open source. Because of machine limitations, I will only be using the smallest(still containing 100-dimensional word vectors for 6 billion words!).\n",
    "\n",
    "### Getting the Total Vocabulary\n",
    "Although our pretrained GloVe data contains vectors for 6 billion words and phrases, we don't need all of them. Instead, we only need the vectors for the words that appear in our dataset. If a word or phrase doesn't appear in our dataset, then there's no reason to waste memory storing the vector for that word or phrase.\n",
    "\n",
    "This means that we need to start by computing the total vocabulary of our dataset. We can do this by adding every word in the dataset into a python set object. This is easy, since we've already tokenized each comment stored within data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocabulary = set(word for headline in data for word in headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 279 unique tokens in our dataset.\n"
     ]
    }
   ],
   "source": [
    "len(total_vocabulary)\n",
    "print(\"There are {} unique tokens in our dataset.\".format(len(total_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = {}\n",
    "with open('glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now have all of the words and their corresponding vocabulary stored within our dictionary, glove, as key/value pairs.\n",
    "let's double check\n",
    "It's probably safe to assume that the word 'senator' will be mentioned in at least one news headline, so let's get the vector for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.39334  ,  0.18748  ,  0.6471   ,  0.14527  ,  0.15966  ,\n",
       "        1.1369   , -0.79629  ,  0.35415  , -0.56611  , -1.0419   ,\n",
       "       -1.5981   , -0.043776 ,  0.13376  , -0.08937  , -0.29572  ,\n",
       "       -0.9005   , -0.12758  ,  0.020343 ,  0.43953  , -0.33088  ,\n",
       "       -0.79181  ,  0.0078458,  0.25937  , -0.46204  ,  0.5987   ,\n",
       "       -2.6559   ,  0.23042  , -0.26325  , -0.63301  ,  0.39607  ,\n",
       "        1.0315   , -0.43104  , -1.1923   , -0.73129  , -0.038077 ,\n",
       "       -1.1653   , -0.42326  ,  0.78656  , -0.20375  , -0.71893  ,\n",
       "       -0.53437  ,  1.1682   , -0.87608  , -0.21386  , -0.45835  ,\n",
       "        0.28739  , -1.1319   , -0.35848  , -0.0080362,  1.5094   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['senator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to combine all the vectors for a given headline into a Mean Embedding by finding the average of all the vectors in that headline.\n",
    "\n",
    "### Creating Mean Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2vVectorizer(object):\n",
    "    \n",
    "    def __init__(self, w2v):\n",
    "        # takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "    # Note: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "    # It can't be used in a sklearn Pipeline. \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf =  Pipeline([(\"Word2Vec Vectorizer\", W2vVectorizer(glove)),\n",
    "              (\"Random Forest\", RandomForestClassifier(n_estimators=100, verbose=True))])\n",
    "\n",
    "svc = Pipeline([(\"Word2Vec Vectorizer\", W2vVectorizer(glove)),\n",
    "                ('Support Vector Machine', SVC())])\n",
    "\n",
    "lr = Pipeline([(\"Word2Vec Vectorizer\", W2vVectorizer(glove)),\n",
    "              ('Logistic Regression', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('Random Forest', rf),\n",
    "          (\"Support Vector Machine\", svc),\n",
    "          (\"Logistic Regression\", lr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.0s finished\n",
      "/Users/nick/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/nick/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/nick/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nick/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/nick/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nick/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "scores = [(name, cross_val_score(model, data, target, cv=2).mean()) for name, model, in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Random Forest', 0.3040862473652662),\n",
       " ('Support Vector Machine', 0.31789813859395244),\n",
       " ('Logistic Regression', 0.3186251591420255)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scores may seem pretty low, but remember that there are 40 (after some feature engineering) possible categories that headlines could be classified into. This means the naive accuracy rate (random guessing) would achieve an accuracy of just over 0.025!(2.5%) Our models have plenty of room for improvement, but they do work!\n",
    "\n",
    "I think it is also worth mentioning that there was not much difference in scores when I ran 20% of data set through the model VS the entire dataset, except that it took much longer (almost 3 hours)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning (With Word Embeddings)\n",
    "\n",
    "First, I import everything we'll need from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then convert our labels to a one-hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(target).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll preprocess our text data. To do this, we start from the step where we combined the headlines and short description. We'll then use Keras's preprocessing tools to tokenize each example, convert them to sequences, and then pad the sequences so they're all the same length.\n",
    "\n",
    "Note how during the tokenization step, we set a parameter to tell the tokenizer to limit our overall vocabulary size to the 20000 most important words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(list(df.combined_text))\n",
    "list_tokenized_headlines = tokenizer.texts_to_sequences(df.combined_text)\n",
    "X_t = sequence.pad_sequences(list_tokenized_headlines, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll construct our neural network. Notice how the Embedding Layer comes second, after the input layer. In the Embedding Layer, we specify the size we want our word vectors to be, as well as the size of the embedding space itself. The embedding size we specified is 128, and the size of the embedding space is best as the size of the total vocabulary that we're using. Since we limited the vocab to 20000, that's the size we choose for the embedding layer.\n",
    "\n",
    "Once our data has passed through an embedding layer, we feed this data into an LSTM layer, followed by a Dense layer, followed by output layer. We also add some Dropout layers after each of these layers, to help fight overfitting.\n",
    "\n",
    "Our output layer is a Dense layer with 40 neurons, which corresponds to the 40 possible classes in our labels. We set the activation function for this output layer to 'softmax', so that our network will output a vector of predictions, where each element's value corresponds to the percentage chance that the example is the class that corresponds to that element, and where the sum of all elements in the output vector is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "input_ = Input(shape=(100,))\n",
    "x = Embedding(20000, embedding_size)(input_)\n",
    "x = LSTM(25, return_sequences=True)(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# There are 40 different possible classes, so we use 41 neurons in our output layer\n",
    "x = Dense(40, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have designed our model, we still have to compile it, and provide important parameters such as the loss function to use ('categorical_crossentropy', since this is a mutliclass classification problem), and the optimizer to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We quickly check the summary of the model to see what our model looks like, and make sure the output shapes line up with what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 25)           15400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                2040      \n",
      "=================================================================\n",
      "Total params: 2,578,740\n",
      "Trainable params: 2,578,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can fit the model by passing in the data, our labels, and setting some other hyperparameters such as the batch size, the number of epochs to train for, and what percentage of the training data to use for validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36153 samples, validate on 4018 samples\n",
      "Epoch 1/10\n",
      "36153/36153 [==============================] - 107s 3ms/step - loss: 2.1910 - accuracy: 0.4193 - val_loss: 2.1853 - val_accuracy: 0.4403\n",
      "Epoch 2/10\n",
      "36153/36153 [==============================] - 106s 3ms/step - loss: 1.9835 - accuracy: 0.4620 - val_loss: 2.1801 - val_accuracy: 0.4495\n",
      "Epoch 3/10\n",
      "36153/36153 [==============================] - 108s 3ms/step - loss: 1.8219 - accuracy: 0.4940 - val_loss: 2.2572 - val_accuracy: 0.4632\n",
      "Epoch 4/10\n",
      "36153/36153 [==============================] - 107s 3ms/step - loss: 1.6947 - accuracy: 0.5248 - val_loss: 2.2839 - val_accuracy: 0.4567\n",
      "Epoch 5/10\n",
      "36153/36153 [==============================] - 107s 3ms/step - loss: 1.5843 - accuracy: 0.5446 - val_loss: 2.3524 - val_accuracy: 0.4562\n",
      "Epoch 6/10\n",
      "36153/36153 [==============================] - 143s 4ms/step - loss: 1.5039 - accuracy: 0.5610 - val_loss: 2.4697 - val_accuracy: 0.4512\n",
      "Epoch 7/10\n",
      "36153/36153 [==============================] - 108s 3ms/step - loss: 1.4223 - accuracy: 0.5790 - val_loss: 2.5487 - val_accuracy: 0.4639\n",
      "Epoch 8/10\n",
      "36153/36153 [==============================] - 105s 3ms/step - loss: 1.3522 - accuracy: 0.5912 - val_loss: 2.8122 - val_accuracy: 0.4709\n",
      "Epoch 9/10\n",
      "36153/36153 [==============================] - 105s 3ms/step - loss: 1.2941 - accuracy: 0.6087 - val_loss: 2.7564 - val_accuracy: 0.4642\n",
      "Epoch 10/10\n",
      "36153/36153 [==============================] - 105s 3ms/step - loss: 1.2506 - accuracy: 0.6219 - val_loss: 2.9638 - val_accuracy: 0.4584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3a119eb8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Models, better known as Recurrent Neural Networks\n",
    "\n",
    "The hallmark of Recurrent Neural Networks is that they are used to evaluate Sequences of data, rather than just individual data points. All text data is sequence data by default--a sentance only makes sense when it's words are in the proper order. Recurrent Neural Networks (RNN) can take in text as full sequences of words, from a single sentence up to an entire document or book! Because of this, they do not suffer the same loss of information that comes from a traditional Bag-of-Words vectorization approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import LSTM, GRU, Dense, GlobalMaxPool1D, Embedding, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(list(data))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(data)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(20000, 128))\n",
    "lstm_model.add(LSTM(50, return_sequences=True))\n",
    "lstm_model.add(GlobalMaxPool1D())\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(50, activation='relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(40, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation Parameters\n",
    "Now that we've built our model, we still need to compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our model, let's take a look at what it looks like, and see how many trainable parameters it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, None, 50)          35800     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 40)                2040      \n",
      "=================================================================\n",
      "Total params: 2,600,390\n",
      "Trainable params: 2,600,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Our Model\n",
    "\n",
    "Now that we have preprocessed our data, created our model, and compiled it, we're ready for the moment of truth--training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nick/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 36153 samples, validate on 4018 samples\n",
      "Epoch 1/5\n",
      "36153/36153 [==============================] - 124s 3ms/step - loss: 3.0242 - accuracy: 0.2319 - val_loss: 2.5963 - val_accuracy: 0.3218\n",
      "Epoch 2/5\n",
      "36153/36153 [==============================] - 120s 3ms/step - loss: 2.4291 - accuracy: 0.3656 - val_loss: 2.2571 - val_accuracy: 0.4019\n",
      "Epoch 3/5\n",
      "36153/36153 [==============================] - 122s 3ms/step - loss: 2.0642 - accuracy: 0.4493 - val_loss: 2.1372 - val_accuracy: 0.4530\n",
      "Epoch 4/5\n",
      "36153/36153 [==============================] - 121s 3ms/step - loss: 1.8090 - accuracy: 0.5079 - val_loss: 2.1312 - val_accuracy: 0.4771\n",
      "Epoch 5/5\n",
      "36153/36153 [==============================] - 122s 3ms/step - loss: 1.6373 - accuracy: 0.5461 - val_loss: 2.2266 - val_accuracy: 0.4798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a5942c438>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(X_t, y, epochs=5, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Our GRU Model\n",
    "\n",
    "Now that we have a benchmark for how an LSTM model performs, let's build the exact same model, but with GRU() cells instead of LSTM() cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model\n",
    "\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(20000, 128))\n",
    "gru_model.add(GRU(50, return_sequences=True))\n",
    "gru_model.add(GlobalMaxPool1D())\n",
    "gru_model.add(Dropout(0.5))\n",
    "gru_model.add(Dense(50, activation='relu'))\n",
    "gru_model.add(Dropout(0.5))\n",
    "gru_model.add(Dense(40, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compile the model with the same parameters we did for the first network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at a .summary() of our GRU model, and see if it has more or less total trainable parameters than our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, None, 50)          26850     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 40)                2040      \n",
      "=================================================================\n",
      "Total params: 2,591,440\n",
      "Trainable params: 2,591,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train our GRU model using the same parameters as we did for our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36153 samples, validate on 4018 samples\n",
      "Epoch 1/5\n",
      "36153/36153 [==============================] - 123s 3ms/step - loss: 3.0236 - accuracy: 0.2337 - val_loss: 2.5191 - val_accuracy: 0.3606\n",
      "Epoch 2/5\n",
      "36153/36153 [==============================] - 122s 3ms/step - loss: 2.3969 - accuracy: 0.3837 - val_loss: 2.2261 - val_accuracy: 0.4216\n",
      "Epoch 3/5\n",
      "36153/36153 [==============================] - 124s 3ms/step - loss: 2.0571 - accuracy: 0.4559 - val_loss: 2.0933 - val_accuracy: 0.4632\n",
      "Epoch 4/5\n",
      "36153/36153 [==============================] - 124s 3ms/step - loss: 1.8342 - accuracy: 0.5050 - val_loss: 2.0682 - val_accuracy: 0.4769\n",
      "Epoch 5/5\n",
      "36153/36153 [==============================] - 122s 3ms/step - loss: 1.6458 - accuracy: 0.5453 - val_loss: 2.1333 - val_accuracy: 0.4843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a330f6e80>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.fit(X_t, y, epochs=5, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the LSTM and GRU models performed about the same on this particular dataset. That is to say that they both did exceptionally well. After only 5 epochs, with only a small fraction of the entire dataset (machine constraints) they where both able to reach accuracy scores of nearly 55%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Sequence Models\n",
    "\n",
    "A Bidirectional RNN is just like a regular RNN, but with a twist--half of the neurons start by at the beginnig of the data and work towards the end one step at a time, while the other half start at the end of the data and work towards the beginning at the same pace. Neat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This cell takes a little while to run!\n",
    "tokenizer = text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(list(data))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(data)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "input_ = Input(shape=(100,))\n",
    "x = Embedding(30000, embedding_size)(input_)\n",
    "x = Bidirectional(LSTM(25, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(40, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(40, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the model we've created. In the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_11 (Embedding)     (None, 100, 128)          3840000   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 100, 50)           30800     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_11 (Glo (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 40)                2040      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 40)                1640      \n",
      "=================================================================\n",
      "Total params: 3,874,480\n",
      "Trainable params: 3,874,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = 'weights_base.best.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoints_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36153 samples, validate on 4018 samples\n",
      "Epoch 1/2\n",
      "36153/36153 [==============================] - 176s 5ms/step - loss: 0.1008 - accuracy: 0.9763 - val_loss: 0.0875 - val_accuracy: 0.9770\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08749, saving model to weights_base.best.hdf5\n",
      "Epoch 2/2\n",
      "36153/36153 [==============================] - 182s 5ms/step - loss: 0.0905 - accuracy: 0.9771 - val_loss: 0.0814 - val_accuracy: 0.9774\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08749 to 0.08138, saving model to weights_base.best.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a8dabbd68>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a Bidirectional LSTM Network\n",
    "model.fit(X_t, y, batch_size=32, epochs=2, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of over 97.7% when trained on only 20% of the data! I think it is pretty safe to say that this model works well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "- I did achieve some level of success with traditional machine learning models. Using pre_trained weights to help speed things up I was able to achieve an accuracy score of a little over 30% for Random Forrest, Logistic Regression, and Support Vector Machine(SVM) respectively. I know if I spent more time playing around with the various weights and parameters, I could have gotten a bit more performance from them, but these were still very time consuming, and I knew that deep learning, and Recurrent Neural Networks were going to be strongest contenders.\n",
    "\n",
    "\n",
    "- My traditional deep learning classification model was a much stronger (and more realistic) right out of the gate. Without having to do much tuning, and still using 20% of the entire dataset (which still took a while) my model was able to achieve after only 10 epochs a training accuracy of over 60% with a Validation accuracy of nearly 50%. At this point, I was already starting to see some sighns of overtraining, as my training score was still slowly getting better, but my Validation score was strting to fall off a bit. I am confident that even keeping with most of my parameters, using more of the dataset, and making some small adjustments to way I preprocessed my data, I could still get a bit more performance out of that type of model. However, this type of fine tuning is still very time (computational and otherwise) consuming, and I knew I had likely saved the best models for last. \n",
    "\n",
    "\n",
    "- When it came time for running the data through a Recurrent Neural Network, I knew I was finally making some real strides. Not that the previous models had not performed admirably, they simply were not the best tool for the job. Both my Long Short Term Memory Cells (LSTU) and Gated Recurrent Units (GRU) models performed nearly as well as one another, which was makedly better than my traditional deep neural network. Because of the way these models work, they are more computationally expensive than my previous model, so again, using only 20% of the dataset, and after only 5 epochs each (half as many) both models where already about to overtake the previous benchmark for training accuracy having scores of well over 50%, but with much stronger validation accuracy. Evan after only 5 iterations though the network, they already Validation accuracy of nearly 50%. While I am confident these models would have only continued to grow stronger with more data and more iterations (to a point), I still had my \"ACE\" up my sleeve, and was ready to see how it performed.\n",
    "\n",
    "\n",
    "- My Bidirectional Sequence Model did amazingly well! With a Validation accuracy of over 97.7% when trained on only 20% of the data! I think it is pretty safe to say that this model all those who came before it. While every model I used on this dataset did progressively better than previous (more simple) models, this particular model is in a class all it's own. I admit that I worked through these various model types in the order that I assumed would get progressively stronger results, but I am plesantly surprised at how strongly this Bidirectional Sequence Model worked. unfortunetly, my old macbook is getting on in years, so I had to pic and choose carefully what to ask of it. doing only 2 epochs of 20% of the data set still took a while to train.... that being said, the model was still getting stronger with each iteration. I am confident that had I ran the entire dataset with 20 or more epochs(on a better computer), I could achieve an accuracy score of well over 98%, and that before playing with all the tunable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "- Continue collecting and adding to the data (always).\n",
    "\n",
    "- Try some different preprocessing techniques on the data before modeling, there are large variety of way to preprocess and \"normalize\" the data before modeling, I only touched on a few.\n",
    "\n",
    "- Continue playing around with the many (many) tunable parameters of the models I am working with, not only to see if it improves the models performance, but alos to gain more insight about whats going on \"under the hood\" so to speak, and get more intuition about whats happening with the underlying data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
